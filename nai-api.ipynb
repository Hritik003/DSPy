{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import time\n",
    "import requests\n",
    "import os\n",
    "import datetime\n",
    "import yaml\n",
    "\n",
    "from rich import print\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "\n",
    "load_dotenv('./.env')\n",
    "nai_api_key = os.getenv('NAI_API_KEY')\n",
    "# print(nai_api_key)\n",
    "hf_api_key = os.getenv('HF_TOKEN')\n",
    "\n",
    "nai_url= 'https://ai.nutanix.com/api/v1/chat/completions'\n",
    "\n",
    "nai_api_key = nai_api_key.strip()\n",
    "\n",
    "def send_inference_request(system_prompt, user_prompt):\n",
    "    inference_input = {\n",
    "        \"model\": \"vllm-llama-3-1\",\n",
    "        \"messages\": [\n",
    "            {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": system_prompt\n",
    "            },\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": user_prompt\n",
    "            }\n",
    "        ],\n",
    "        \"max_tokens\": 1024,\n",
    "        \"stream\": False\n",
    "    }\n",
    "\n",
    "    response = requests.post(nai_url, \n",
    "                            headers={\n",
    "                                    \"Authorization\": f\"Bearer {nai_api_key}\", \n",
    "                                    \"accept\": \"application/json\",\n",
    "                                    \"Content-Type\": \"application/json\"\n",
    "                                }, \n",
    "                            json=inference_input, \n",
    "                            verify=False)\n",
    "    return response.json()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "source_code_file = 'codegen-observation/hritik/cluster.go/cluster.go'\n",
    "source_code_manual_unit_test_file ='codegen-observation/hritik/cluster.go/cluster_test.go'\n",
    "source_code_codegen_unit_test_file = 'codegen-observation/hritik/cluster.go/cluster_test_codegen.go'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('Prompts/prompt_01.yaml', 'r') as file:\n",
    "    prompts = yaml.safe_load(file)\n",
    "\n",
    "with open(source_code_file, 'r') as source_file:\n",
    "    go_source_code = source_file.read()\n",
    "\n",
    "with open(source_code_manual_unit_test_file, 'r') as test_file:\n",
    "    go_unit_test_code = test_file.read()\n",
    "\n",
    "with open(source_code_codegen_unit_test_file, 'r') as test_file:\n",
    "    go_unit_test_code = test_file.read()\n",
    "    \n",
    "# print(prompts)\n",
    "system_prompt = prompts.get('system_prommpt','')\n",
    "\n",
    "user_prompt = prompts.get('user_prompt', '')\n",
    "user_prompt = user_prompt.replace('<GO_SOURCE_CODE>', go_source_code).replace('<GO_MANUAL_UNIT_TEST_CODE>', source_code_manual_unit_test_file).replace('<GO_COPILOT_UNIT_TEST_CODE>',source_code_codegen_unit_test_file)\n",
    "\n",
    "# print(user_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response_from_model = send_inference_request(system_prompt=system_prompt, user_prompt=user_prompt)[\"choices\"][0][\"message\"][\"content\"]\n",
    "\n",
    "with open('./Responses/response_01.txt', 'w') as file:\n",
    "    file.write(response_from_model)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feedback prompt to the model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feedback from prompt 1 to 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./Prompts/Prompt_02.yaml','r') as file:\n",
    "    feedback_prompt = yaml.safe_load(file)\n",
    "    \n",
    "\n",
    "with open('./Responses/response_01.yaml','r') as file:\n",
    "    response_from_prompt_1 = yaml.safe_load(file)\n",
    "    \n",
    "feedback_system_prompt = feedback_prompt.get('system_prompt','')\n",
    "\n",
    "feedback_user_prompt = feedback_prompt.get('user_prompt','').replace('<CHANGES_NEEDED>',response_from_prompt_1).replace('<GO_UNIT_TEST_CODE>', go_unit_test_code)\n",
    "\n",
    "# print(feedback_user_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hritik.raj/codegen-nai/.venv/lib/python3.12/site-packages/urllib3/connectionpool.py:1099: InsecureRequestWarning: Unverified HTTPS request is being made to host 'ai.nutanix.com'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "inference_input = {\n",
    "    \"model\": \"vllm-llama-3-1\",\n",
    "    \"messages\": [\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": feedback_system_prompt\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": feedback_user_prompt\n",
    "        }\n",
    "    ],\n",
    "    \"max_tokens\": 256,\n",
    "    \"stream\": False\n",
    "}\n",
    "\n",
    "response = requests.post(nai_url, \n",
    "                         headers={\n",
    "                                \"Authorization\": f\"Bearer {nai_api_key}\", \n",
    "                                \"accept\": \"application/json\",\n",
    "                                \"Content-Type\": \"application/json\"\n",
    "                            }, \n",
    "                         json=inference_input, \n",
    "                         verify=False)\n",
    "\n",
    "\n",
    "feeback_response_from_model = response.json()[\"choices\"][0][\"message\"][\"content\"]\n",
    "\n",
    "with open('./Responses/response_02.yaml','w') as file:\n",
    "    yaml.dump(feeback_response_from_model, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
